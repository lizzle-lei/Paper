<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>20220323——论文阅读 &mdash; Lizzle 0.1 documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="D2L" href="../D2L/index.html" />
    <link rel="prev" title="20220322——论文阅读" href="20220322.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Lizzle
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../CSAPP/index.html">CSAPP</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">论文阅读</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="reading_tips.html">怎么读论文–by 李沐</a></li>
<li class="toctree-l2"><a class="reference internal" href="20220317.html">20220317——论文阅读</a></li>
<li class="toctree-l2"><a class="reference internal" href="20220318.html">20220318——论文阅读</a></li>
<li class="toctree-l2"><a class="reference internal" href="20220322.html">20220322——论文阅读</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">20220323——论文阅读</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#meta-learning-on-heterogeneous-information-networks-for-cold-start-recommendation">Meta-learning on Heterogeneous Information Networks for Cold-start Recommendation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fairness-among-new-items-in-cold-start-recommender-systems">Fairness among New Items in Cold Start Recommender Systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="#learning-graph-meta-embeddings-for-cold-start-ads-in-click-through-rate-prediction">Learning Graph Meta Embeddings for Cold-Start Ads in Click-Through Rate Prediction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#learning-to-warm-up-cold-item-embeddings-for-cold-start-recommendation-with-meta-scaling-and-shifting-networks">Learning to Warm Up Cold Item Embeddings for Cold-start Recommendation with Meta Scaling and Shifting Networks</a></li>
<li class="toctree-l3"><a class="reference internal" href="#sparsity-regularization-for-cold-start-recommendation">Sparsity Regularization for Cold-Start Recommendation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#metakg-meta-learning-on-knowledge-graph-for-cold-start-recommendation">MetaKG: Meta-learning on Knowledge Graph for Cold-start Recommendation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#task-adaptive-neural-process-for-user-cold-start-recommendation">Task-adaptive Neural Process for User Cold-Start Recommendation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#collaborative-filtering-with-attribution-alignment-for-review-based-non-overlapped-cross-domain-recommendation">Collaborative Filtering with Attribution Alignment for Review-based Non-overlapped Cross Domain Recommendation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#a-deep-framework-for-cross-domain-and-cross-system-recommendations">A Deep Framework for Cross-Domain and Cross-System Recommendations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#methods-and-metrics-for-cold-start-recommendations">Methods and Metrics for Cold-Start Recommendations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#grouplens-an-open-architecture-for-collaborative-filtering-of-netnews">GroupLens: An Open Architecture for Collaborative Filtering of Netnews</a></li>
<li class="toctree-l3"><a class="reference internal" href="#using-collabrative-filtering-to-weave-an-information-typestry">Using collabrative filtering to weave an information typestry</a></li>
<li class="toctree-l3"><a class="reference internal" href="#wide-deep-learning-for-recommender-systems">Wide &amp; Deep Learning for Recommender Systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cross-domain-generalization-and-knowledge-transfer-in-transformers-trained-on-legal-data">Cross-Domain Generalization and Knowledge Transfer in Transformers Trained on Legal Data</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../D2L/index.html">D2L</a></li>
<li class="toctree-l1"><a class="reference internal" href="../%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/index.html">刷题记录</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Lizzle</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">论文阅读</a> &raquo;</li>
      <li>20220323——论文阅读</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/Daily_Reading/20220323.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="id1">
<h1>20220323——论文阅读<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<div class="section" id="meta-learning-on-heterogeneous-information-networks-for-cold-start-recommendation">
<h2>Meta-learning on Heterogeneous Information Networks for Cold-start Recommendation<a class="headerlink" href="#meta-learning-on-heterogeneous-information-networks-for-cold-start-recommendation" title="Permalink to this headline">¶</a></h2>
<p>本文的代码：<a class="reference external" href="https://github.com/rootlu/MetaHIN">https://github.com/rootlu/MetaHIN</a></p>
<p>这篇文章来自于北京邮电大学，其涉及微信搜索与应用部门的合作。作者是Lu Yuanfu, Yuan Fang, Chuan Shi
文章发表在2020年的KDD上。</p>
<p>其在数据层面和模型层面解决了冷启动问题。</p>
<p>1、元学习阶段，在HIN上捕获语义信息。
在meta-learing阶段设计了一个语义增强的任务构造器在HIN上挖掘更多的语义信息。</p>
<p>2.如果学习得到一个general knowledge，可以适应多个层面的语义
一个共同适应的元学习者，语义和任务层面的适应，以解决不同任务的语义层面的信息。</p>
<p>元学习是用来解决model level，HIN用来解决的data level.</p>
</div>
<div class="section" id="fairness-among-new-items-in-cold-start-recommender-systems">
<h2>Fairness among New Items in Cold Start Recommender Systems<a class="headerlink" href="#fairness-among-new-items-in-cold-start-recommender-systems" title="Permalink to this headline">¶</a></h2>
<p>这篇文章是讲新项目在冷启动中的公平性Fairness的，与毕设选题关系较小，没有阅读</p>
<p>文章发表在2021年的SIGIR上，作者来自于Texas A&amp;M University和Netflix</p>
</div>
<div class="section" id="learning-graph-meta-embeddings-for-cold-start-ads-in-click-through-rate-prediction">
<h2>Learning Graph Meta Embeddings for Cold-Start Ads in Click-Through Rate Prediction<a class="headerlink" href="#learning-graph-meta-embeddings-for-cold-start-ads-in-click-through-rate-prediction" title="Permalink to this headline">¶</a></h2>
<p>这篇文章发布在2021年的SIGIR，研究者来自于Alibaba Group</p>
<p>其主要是研究在advertising systems中的Click-Through rate Prediction.</p>
<p>其主要是集中在Embedding的层面
快速的学习生成intial Embeddings for new ad IDs 基于graph nerual networks and meta learning.
其同时考虑了新的广告信息以及已经存在的旧的广告信息，GNEs通过创建一个graph来讲new ads 和old ads的信息联系起来。</p>
</div>
<div class="section" id="learning-to-warm-up-cold-item-embeddings-for-cold-start-recommendation-with-meta-scaling-and-shifting-networks">
<h2>Learning to Warm Up Cold Item Embeddings for Cold-start Recommendation with Meta Scaling and Shifting Networks<a class="headerlink" href="#learning-to-warm-up-cold-item-embeddings-for-cold-start-recommendation-with-meta-scaling-and-shifting-networks" title="Permalink to this headline">¶</a></h2>
<p>这篇文章发表在2021年的SIGIR上，其来自于zhu yongchun同学，通讯作者是庄福振老师。</p>
<p>又是一篇关于冷启动的文章，针对于Cold Item Embedding</p>
<p>文章想要解决什么样的问题呢？</p>
<p>1、A gap is existing between the cold ID  Embedding and the deep model.</p>
<p>采取的解决方案：Speed up the model fitting for the cold item ID embedding(fast adaptation).</p>
<p>2、Cold ID embedding would be seriously affected by noisy interaction.
采取的解决方案：Alleviate the influence of noise.</p>
<p>Meta Scaling and Shifting Networks.</p>
<p>1、the scaling function 将cold item ID embedding 转向 warm feature space</p>
<p>2、the shifting networks produce stable embeddings from noisy embeddings.</p>
<p>Meta Warm up Framework(MWUF)：Learn to warm up cold ID embedding.</p>
<p>这篇文章的思想是不是可以迁移到用户的embedding上面呢？</p>
</div>
<div class="section" id="sparsity-regularization-for-cold-start-recommendation">
<h2>Sparsity Regularization for Cold-Start Recommendation<a class="headerlink" href="#sparsity-regularization-for-cold-start-recommendation" title="Permalink to this headline">¶</a></h2>
<p>这篇文章还没有发表，其是2022年1月28日提交到arxiv上面的。研究者来自于
Arizona State University.</p>
<p>a novel representation for user-vectors by combining user demographics and user preference</p>
<p>其使用用户的购买行为而不是互动信息。</p>
<p>develop a novel sparse adversarial model.</p>
<p>使用到了一个KL-divergence作为惩罚稀疏。</p>
</div>
<div class="section" id="metakg-meta-learning-on-knowledge-graph-for-cold-start-recommendation">
<h2>MetaKG: Meta-learning on Knowledge Graph for Cold-start Recommendation<a class="headerlink" href="#metakg-meta-learning-on-knowledge-graph-for-cold-start-recommendation" title="Permalink to this headline">¶</a></h2>
<p>这是一篇未发表的文章，来自高云君和陈璐老师的团队，2022年2月8日提交在arXiv上面。
论文的代码可见：<a class="reference external" href="https://github.com/ZJU-DBL/MetaKG">https://github.com/ZJU-DBL/MetaKG</a></p>
<p>其第一次将meta-learing应用在KG上面，其主要设计了一个collaboratie-aware meta learner：学习用户在每个任务中的preference和一个knowledge-aware meta learner:在KG当中，不同任务的语义表示。</p>
</div>
<div class="section" id="task-adaptive-neural-process-for-user-cold-start-recommendation">
<h2>Task-adaptive Neural Process for User Cold-Start Recommendation<a class="headerlink" href="#task-adaptive-neural-process-for-user-cold-start-recommendation" title="Permalink to this headline">¶</a></h2>
<p>这篇文章发表在2021年的International World Wide Web Conference上。
第一作者来自于信工所和网安，其他研究者有来自于澳大利亚麦考瑞大学，小米人工智能实验室，Monash University，数据与系统科学研究院
通讯作者为周川</p>
<p>a corresponding stochastic process：一个相应的随机过程。
作者提出了一个模型：TaNP</p>
<p>其能够maps the observed interactions of each user to a predictive distribution, sidestepping some training issues in gradient-based meta-learing models.
其还设计了Task-adaptive mechanism，其能够学习不同任务之间的相关性，定制全局的知识到与任务相关的解码器中。</p>
<p>代码的链接：<a class="reference external" href="https://github.com/IIEdm/TaNP">https://github.com/IIEdm/TaNP</a></p>
<p>一些代码的网址：
<a class="reference external" href="https://github.com/hexiangnan/neural_collaborative_filtering">https://github.com/hexiangnan/neural_collaborative_filtering</a>
<a class="reference external" href="https://github.com/layer6ai-labs/DropoutNet">https://github.com/layer6ai-labs/DropoutNet</a>
<a class="reference external" href="https://github.com/hoyeoplee/MeLU">https://github.com/hoyeoplee/MeLU</a>
<a class="reference external" href="https://github.com/rootlu/MetaHIN">https://github.com/rootlu/MetaHIN</a>
<a class="reference external" href="https://github.com/dongmanqing/Code-for-MAMO">https://github.com/dongmanqing/Code-for-MAMO</a></p>
</div>
<div class="section" id="collaborative-filtering-with-attribution-alignment-for-review-based-non-overlapped-cross-domain-recommendation">
<h2>Collaborative Filtering with Attribution Alignment for Review-based Non-overlapped Cross Domain Recommendation<a class="headerlink" href="#collaborative-filtering-with-attribution-alignment-for-review-based-non-overlapped-cross-domain-recommendation" title="Permalink to this headline">¶</a></h2>
<p>这篇是来自浙江大学郑小林和陈超超老师的团队，发表在2022年的WWW会议上</p>
<p>文章基于Review-based Non-overlapped Recommendation.</p>
<p>在目标域中只有积极的用户-项目评分（这个会带来什么问题呢？）</p>
<p>在不同的域之间没有重叠的用户。</p>
<p>目前有关RNCDR问题有哪些不足呢？
1、不能将评论信息与其他信息进行结合去表示user embedding 和 item embedding</p>
<p>2、他们不能减少不同域用户和项目之间的差异。</p>
<p>文章提出的模型是Collaborative Filtering with Attribution Alignment model(归因对齐)
其由两部分组成，一部分是rating perdiction module, 实现信息的聚合；
另一部分是embedding attribution alignment module，其能够实现
vertical attribution aligment: 利用典型的样本选择和最优transport使得跨域一致。
和 horizontal attribution alignment：利用具有归因图对齐的子空间建模来减少差异。</p>
</div>
<div class="section" id="a-deep-framework-for-cross-domain-and-cross-system-recommendations">
<h2>A Deep Framework for Cross-Domain and Cross-System Recommendations<a class="headerlink" href="#a-deep-framework-for-cross-domain-and-cross-system-recommendations" title="Permalink to this headline">¶</a></h2>
<p>这篇来自于澳大利亚麦考瑞大学，合作的单位有蚂蚁金服（Chen chaochao）。
文章发表在2018年的IJCAI上。</p>
<p>目标是实现跨域（CDR）和跨系统（CSR）推荐</p>
<p>这里重点关注跨域推荐（CDR）</p>
<p>其提出的一个算法框架的流程：</p>
<ol class="arabic simple">
<li><p>利用矩阵分解源域与目标域的评分矩阵，将其分为{U^s, V^s,U^t, V^t}</p></li>
<li><p>考虑到数据之间存在稀疏性问题，分别计算共同用户和非共同用户的评分稀疏度，利用t,Us和稀疏度系数构建形成用户的标准矩阵基准因子矩阵【基准矩阵】U^b。
【目的是将源域和目标域中的共同用户做一个综合表示。】</p></li>
<li><p>利用全连接的深度学习网络，寻找目标域用户矩阵U^t 到用户标准矩阵U^b的映射关系，最终输出结果hat U^t。</p></li>
<li><p>基于矩阵分解，fix(固定) hat U^t，对V^t进行优化，得到hat V^t。将hat U^t * hat V^t 得到最终预测的评分矩阵hat R^t 。</p></li>
</ol>
<p>其中有一个点没有明白，为什么要得到这个标准的矩阵U^b，以及这个标准的矩阵为什么是这么实现的，它给我的感觉是通过数据集的稀疏程度，得到权重，并将分解得到源域与目标域的矩阵按照权重相加得到U^b。</p>
</div>
<div class="section" id="methods-and-metrics-for-cold-start-recommendations">
<h2>Methods and Metrics for Cold-Start Recommendations<a class="headerlink" href="#methods-and-metrics-for-cold-start-recommendations" title="Permalink to this headline">¶</a></h2>
<p>这篇文章发表在2002年的SIGIR上，已经过去了有20年了
研究团队来自于宾夕法尼亚大学</p>
<p>研究方法：将content和collaborative data相结合，利用一个probabilistic framework来实现，其中content主要是用来实现item的冷启动问题的。</p>
</div>
<div class="section" id="grouplens-an-open-architecture-for-collaborative-filtering-of-netnews">
<h2>GroupLens: An Open Architecture for Collaborative Filtering of Netnews<a class="headerlink" href="#grouplens-an-open-architecture-for-collaborative-filtering-of-netnews" title="Permalink to this headline">¶</a></h2>
<p>文章发表在1994年，来自MIT，其介绍了GroupLens这个系统，其主要将协同过滤算法应用到了新闻推荐。</p>
</div>
<div class="section" id="using-collabrative-filtering-to-weave-an-information-typestry">
<h2>Using collabrative filtering to weave an information typestry<a class="headerlink" href="#using-collabrative-filtering-to-weave-an-information-typestry" title="Permalink to this headline">¶</a></h2>
<p>文章发表在1992年，这篇文章首次提出了将collaborative_filtering应用到邮件过滤系统Typesry中</p>
</div>
<div class="section" id="wide-deep-learning-for-recommender-systems">
<h2>Wide &amp; Deep Learning for Recommender Systems<a class="headerlink" href="#wide-deep-learning-for-recommender-systems" title="Permalink to this headline">¶</a></h2>
<p>这篇文章来自于Google,有很多的作者。其发表在2016年的DLRS会议上。</p>
<p>研究方法：同时解决Motivation和Generaliztion</p>
<ul class="simple">
<li><p>Memorization</p></li>
</ul>
<p>LR模型：将原始的sparse特征和叉乘特征作为输入，</p>
<p>通过两个特征向量的叉乘，来构造非线性的特征。</p>
<p>局限性：1. 可能需要更多的人工设计 2. 可能出现过拟合。如果将所有特征叉乘起来，那么几乎相当于纯粹的记住每个训练样本，这个极端情况是最细粒度的叉乘，我们可以通过构造更粗力度的特征交叉来增强泛化性。 3. 无法捕捉在训练数据中未曾出现过的特征对。</p>
<ul class="simple">
<li><p>Generalization</p></li>
</ul>
<p>Generalization的目的是为稀疏的特征学习得到低维的embedding来捕获特征的相关性。这类模型可以是DNN和FM</p>
<p>优点：更少的人工参与，对历史上没有出现的特征组合有更好的泛化性。</p>
<p>局限性：当user-item matrix非常稀疏时，例如有独特爱好的users以及很小众的items，NN很难为users和items学习得到有效的embedding。在这种情况下，大部分的user-item应该是没有关联的，但稠密的embedding的方法还是可以对所有的user-item pair的非零预测，因此导致over-generalize并推荐不怎么相关的物品。此时Memorization就展示了优势，其可以记住这些特殊的组合。</p>
<p><strong>Memorization根据历史行为数据，产生的推荐通常和用户已有行为的物品直接相关的物品。而Generalization会学习新的特征组合，提高推荐物品的多样性。</strong></p>
<ul class="simple">
<li><p>Wide部分利用广义的线性模型</p></li>
<li><p>Deep部分利用前馈神经网络</p></li>
</ul>
<p>网络对一些稀疏的特征学习得到一个稠密的embedding，然后和一些原始的稠密特征一起作为网络的输入。</p>
<ul>
<li><p>采用联合训练（Joint Training）和集成（Ensemble）</p></li>
<li><dl class="simple">
<dt>集成Ensemble</dt><dd><ul class="simple">
<li><p>每个模型单独训练，再将模型的结果汇总</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>联合训练的wide部分只需要作一小部分的特征叉乘来弥补deep部分的不足，不需要 一个full-size 的wide 模型</p></li>
<li><p>在论文中，作者通过梯度的反向传播，使用 mini-batch stochastic optimization 训练参数，并对wide部分使用带L1正则的Follow- the-regularized-leader (FTRL) 算法，对deep部分使用 AdaGrad算法。</p></li>
<li><dl>
<dt>特征叉乘 ： 被推荐的app X 用户下载的app【用户历史下载的app list】</dt><dd><ul class="simple">
<li><p>其中用户历史下载的app list 和被推荐的app list都是一个multi-hot特征，假设app的空间为N，叉乘后的Wide的特征总维数为N*N，wide部分直接学每个特征维度的权重就可以了，只是没出现的特征权重都是0。</p></li>
</ul>
<p><strong>Google团队提出了Wide&amp;Deep模型，其将线性模型和深度学习模型相结合，通过联合训练来提升模型整体的性能。其中线性模型具有记忆性，能够根据用户的历史数据，为用户推荐与其历史行为相关的物品。而深度学习模型具有泛化性，能够探索得到历史数据中的隐性关联，提高推荐物品的多样性。</strong></p>
</dd>
</dl>
</li>
</ul>
</div>
<div class="section" id="cross-domain-generalization-and-knowledge-transfer-in-transformers-trained-on-legal-data">
<h2>Cross-Domain Generalization and Knowledge Transfer in Transformers Trained on Legal Data<a class="headerlink" href="#cross-domain-generalization-and-knowledge-transfer-in-transformers-trained-on-legal-data" title="Permalink to this headline">¶</a></h2>
<p>作者： Jarom´ ırˇSA VELKA（Carnegie Mellon University）
录取会议： 未发表，于2021年12月发布在arXiv上</p>
<p>研究方法：其利用在其他域中学习得到的信息，将其应用到法律文件领域。</p>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="20220322.html" class="btn btn-neutral float-left" title="20220322——论文阅读" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../D2L/index.html" class="btn btn-neutral float-right" title="D2L" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, lizzle.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>